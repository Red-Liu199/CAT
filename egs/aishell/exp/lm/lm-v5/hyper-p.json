{
    "data": {
        "train": "train",
        "dev": "dev",
        "test": [
            "dev",
            "test"
        ]
    },
    "tokenizer": {
        "type": "SentencePieceTokenizer",
        "file": "exp/rnnt/rnnt-v15/tokenizer.tknz",
        "|V|": 4232
    },
    "inference": {},
    "commit": "fbce69aa90bed4c3b04de4eaafccbd35a2916368"
}