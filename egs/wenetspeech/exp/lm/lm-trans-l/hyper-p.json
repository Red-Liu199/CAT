{
    "data": {
        "train": "data/train_l.txt",
        "test": [
            "aishell-test",
            "test_net",
            "test_meeting"
        ],
        "lang": "zh-cn"
    },
    "tokenizer": {
        "type": "SentencePieceTokenizer",
        "location": "exp/rnnt/rnnt-v4/tokenizer.tknz"
    },
    "commit": "e1b5a63b4e7ee6f01953b9ed23717690845f7b10"
}