{
    "data": {
        "train": "data/extra.corpus"
    },
    "tokenizer": {
        "type": "SimpleTokenizer",
        "option-init": {
            "dmap": "exp/asr-ctc-crf-phone/decode_lm/lexicon.txt",
            "read_index_from_file": false
        },
        "|V|": 127924,
        "file": "exp/asr-ctc-crf-phone/decode_lm/tokenizer.tknz"
    },
    "inference": {},
    "commit": "none"
}