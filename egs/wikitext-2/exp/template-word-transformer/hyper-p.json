{
    "data": {
        "train": "data/train",
        "dev": "data/valid",
        "test": "data/test",
        "text_processing": {
            "truncate": 35
        }
    },
    "tokenizer": {
        "type": "SentencePieceTokenizer",
        "property": {
            "model_type": "word",
            "vocab_size": 28779,
            "use_all_vocab": true,
            "model_prefix": "sentencepiece/wikitext2-word/spm"
        }
    },
    "train": {
        "batch_size": 20,
        "grad-norm": 0.5,
        "amp": false
    }
}